{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name:- Ankit Kuamr\n",
        "Roll no.:- 1323578\n",
        "Trainer Name:- Lokesh Sir"
      ],
      "metadata": {
        "id": "FG4r9QvLvlDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Title- \"Breast cancer classification using machine learning algorithims (Decision Tree,Random Forest, SVM, and Naive Bayes)\""
      ],
      "metadata": {
        "id": "4RsYIh0jvZ-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PROBLEM STATEMENT:\n",
        "\n",
        "Breast cancer is one of the most common types of cancer among women worldwide. Early detection and accurate diagnosis are crucial for effective treatment and improving survival rates. This project aims to develop and compare the performance of various machine learning algorithms to classify breast cancer tumors as either malignant or benign. The algorithms include Decision Tree, Random Forest, Support Vector Machine (SVM), Kernel SVM, and Naive Bayes.\n",
        "\n",
        "The goal is to identify the most effective model for accurate classification, providing insights into the strengths and weaknesses of each algorithm. This will assist medical practitioners in making informed decisions based on the predictions of the models."
      ],
      "metadata": {
        "id": "qNMSGlZFxM_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Description:\n",
        "\n",
        "Breast cancer is the most common cancer amongst women in the world. It accounts for 25% of all cancer cases, and affected over 2.1 Million people in 2015 alone. It starts when cells in the breast begin to grow out of control. These cells usually form tumors that can be seen via X-ray or felt as lumps in the breast area.\n",
        "\n",
        "The key challenges against itâ€™s detection is how to classify tumors into malignant (cancerous) or benign(non cancerous). We ask you to complete the analysis of classifying these tumors using machine learning (with SVMs) and the Breast Cancer Wisconsin (Diagnostic) Dataset.\n",
        "\n",
        "## Acknowledgements:\n",
        "\n",
        "This dataset has been referred from Kaggle.\n",
        "\n",
        "Objective:\n",
        "Understand the Dataset & cleanup (if required).\n",
        "Build classification models to predict whether the cancer type is Malignant or Benign.\n",
        "Also fine-tune the hyperparameters & compare the evaluation metrics of various classification algorithms."
      ],
      "metadata": {
        "id": "Zxm71z3Mxezl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Methodology"
      ],
      "metadata": {
        "id": "gfOV6IR8xjBf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Import Dependencies"
      ],
      "metadata": {
        "id": "H4CrQL37ySbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report,  confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "2OyEFLg3yEKY"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Reading and Loading Dataset"
      ],
      "metadata": {
        "id": "wWpBZdcFy28n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('BreastCancer.csv')"
      ],
      "metadata": {
        "id": "-bH-pUYPy2KJ"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Apply EDA"
      ],
      "metadata": {
        "id": "dwmItkCPzCDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "KLBedNwnzGQJ",
        "outputId": "4dc552ed-40ed-4a4d-88af-b05b605ae0d8"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of            id diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "0      842302         M  ...          0.4601                  0.11890\n",
              "1      842517         M  ...          0.2750                  0.08902\n",
              "2    84300903         M  ...          0.3613                  0.08758\n",
              "3    84348301         M  ...          0.6638                  0.17300\n",
              "4    84358402         M  ...          0.2364                  0.07678\n",
              "..        ...       ...  ...             ...                      ...\n",
              "564    926424         M  ...          0.2060                  0.07115\n",
              "565    926682         M  ...          0.2572                  0.06637\n",
              "566    926954         M  ...          0.2218                  0.07820\n",
              "567    927241         M  ...          0.4087                  0.12400\n",
              "568     92751         B  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 32 columns]>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.generic.NDFrame.describe</b><br/>def describe(percentiles=None, include=None, exclude=None) -&gt; Self</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py</a>Generate descriptive statistics.\n",
              "\n",
              "Descriptive statistics include those that summarize the central\n",
              "tendency, dispersion and shape of a\n",
              "dataset&#x27;s distribution, excluding ``NaN`` values.\n",
              "\n",
              "Analyzes both numeric and object series, as well\n",
              "as ``DataFrame`` column sets of mixed data types. The output\n",
              "will vary depending on what is provided. Refer to the notes\n",
              "below for more detail.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "percentiles : list-like of numbers, optional\n",
              "    The percentiles to include in the output. All should\n",
              "    fall between 0 and 1. The default is\n",
              "    ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
              "    75th percentiles.\n",
              "include : &#x27;all&#x27;, list-like of dtypes or None (default), optional\n",
              "    A white list of data types to include in the result. Ignored\n",
              "    for ``Series``. Here are the options:\n",
              "\n",
              "    - &#x27;all&#x27; : All columns of the input will be included in the output.\n",
              "    - A list-like of dtypes : Limits the results to the\n",
              "      provided data types.\n",
              "      To limit the result to numeric types submit\n",
              "      ``numpy.number``. To limit it instead to object columns submit\n",
              "      the ``numpy.object`` data type. Strings\n",
              "      can also be used in the style of\n",
              "      ``select_dtypes`` (e.g. ``df.describe(include=[&#x27;O&#x27;])``). To\n",
              "      select pandas categorical columns, use ``&#x27;category&#x27;``\n",
              "    - None (default) : The result will include all numeric columns.\n",
              "exclude : list-like of dtypes or None (default), optional,\n",
              "    A black list of data types to omit from the result. Ignored\n",
              "    for ``Series``. Here are the options:\n",
              "\n",
              "    - A list-like of dtypes : Excludes the provided data types\n",
              "      from the result. To exclude numeric types submit\n",
              "      ``numpy.number``. To exclude object columns submit the data\n",
              "      type ``numpy.object``. Strings can also be used in the style of\n",
              "      ``select_dtypes`` (e.g. ``df.describe(exclude=[&#x27;O&#x27;])``). To\n",
              "      exclude pandas categorical columns, use ``&#x27;category&#x27;``\n",
              "    - None (default) : The result will exclude nothing.\n",
              "\n",
              "Returns\n",
              "-------\n",
              "Series or DataFrame\n",
              "    Summary statistics of the Series or Dataframe provided.\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.count: Count number of non-NA/null observations.\n",
              "DataFrame.max: Maximum of the values in the object.\n",
              "DataFrame.min: Minimum of the values in the object.\n",
              "DataFrame.mean: Mean of the values.\n",
              "DataFrame.std: Standard deviation of the observations.\n",
              "DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
              "    columns based on their dtype.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "For numeric data, the result&#x27;s index will include ``count``,\n",
              "``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
              "upper percentiles. By default the lower percentile is ``25`` and the\n",
              "upper percentile is ``75``. The ``50`` percentile is the\n",
              "same as the median.\n",
              "\n",
              "For object data (e.g. strings or timestamps), the result&#x27;s index\n",
              "will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
              "is the most common value. The ``freq`` is the most common value&#x27;s\n",
              "frequency. Timestamps also include the ``first`` and ``last`` items.\n",
              "\n",
              "If multiple object values have the highest count, then the\n",
              "``count`` and ``top`` results will be arbitrarily chosen from\n",
              "among those with the highest count.\n",
              "\n",
              "For mixed data types provided via a ``DataFrame``, the default is to\n",
              "return only an analysis of numeric columns. If the dataframe consists\n",
              "only of object and categorical data without any numeric columns, the\n",
              "default is to return an analysis of both the object and categorical\n",
              "columns. If ``include=&#x27;all&#x27;`` is provided as an option, the result\n",
              "will include a union of attributes of each type.\n",
              "\n",
              "The `include` and `exclude` parameters can be used to limit\n",
              "which columns in a ``DataFrame`` are analyzed for the output.\n",
              "The parameters are ignored when analyzing a ``Series``.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Describing a numeric ``Series``.\n",
              "\n",
              "&gt;&gt;&gt; s = pd.Series([1, 2, 3])\n",
              "&gt;&gt;&gt; s.describe()\n",
              "count    3.0\n",
              "mean     2.0\n",
              "std      1.0\n",
              "min      1.0\n",
              "25%      1.5\n",
              "50%      2.0\n",
              "75%      2.5\n",
              "max      3.0\n",
              "dtype: float64\n",
              "\n",
              "Describing a categorical ``Series``.\n",
              "\n",
              "&gt;&gt;&gt; s = pd.Series([&#x27;a&#x27;, &#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; s.describe()\n",
              "count     4\n",
              "unique    3\n",
              "top       a\n",
              "freq      2\n",
              "dtype: object\n",
              "\n",
              "Describing a timestamp ``Series``.\n",
              "\n",
              "&gt;&gt;&gt; s = pd.Series([\n",
              "...     np.datetime64(&quot;2000-01-01&quot;),\n",
              "...     np.datetime64(&quot;2010-01-01&quot;),\n",
              "...     np.datetime64(&quot;2010-01-01&quot;)\n",
              "... ])\n",
              "&gt;&gt;&gt; s.describe()\n",
              "count                      3\n",
              "mean     2006-09-01 08:00:00\n",
              "min      2000-01-01 00:00:00\n",
              "25%      2004-12-31 12:00:00\n",
              "50%      2010-01-01 00:00:00\n",
              "75%      2010-01-01 00:00:00\n",
              "max      2010-01-01 00:00:00\n",
              "dtype: object\n",
              "\n",
              "Describing a ``DataFrame``. By default only numeric fields\n",
              "are returned.\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame({&#x27;categorical&#x27;: pd.Categorical([&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;]),\n",
              "...                    &#x27;numeric&#x27;: [1, 2, 3],\n",
              "...                    &#x27;object&#x27;: [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]\n",
              "...                    })\n",
              "&gt;&gt;&gt; df.describe()\n",
              "       numeric\n",
              "count      3.0\n",
              "mean       2.0\n",
              "std        1.0\n",
              "min        1.0\n",
              "25%        1.5\n",
              "50%        2.0\n",
              "75%        2.5\n",
              "max        3.0\n",
              "\n",
              "Describing all columns of a ``DataFrame`` regardless of data type.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(include=&#x27;all&#x27;)  # doctest: +SKIP\n",
              "       categorical  numeric object\n",
              "count            3      3.0      3\n",
              "unique           3      NaN      3\n",
              "top              f      NaN      a\n",
              "freq             1      NaN      1\n",
              "mean           NaN      2.0    NaN\n",
              "std            NaN      1.0    NaN\n",
              "min            NaN      1.0    NaN\n",
              "25%            NaN      1.5    NaN\n",
              "50%            NaN      2.0    NaN\n",
              "75%            NaN      2.5    NaN\n",
              "max            NaN      3.0    NaN\n",
              "\n",
              "Describing a column from a ``DataFrame`` by accessing it as\n",
              "an attribute.\n",
              "\n",
              "&gt;&gt;&gt; df.numeric.describe()\n",
              "count    3.0\n",
              "mean     2.0\n",
              "std      1.0\n",
              "min      1.0\n",
              "25%      1.5\n",
              "50%      2.0\n",
              "75%      2.5\n",
              "max      3.0\n",
              "Name: numeric, dtype: float64\n",
              "\n",
              "Including only numeric columns in a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(include=[np.number])\n",
              "       numeric\n",
              "count      3.0\n",
              "mean       2.0\n",
              "std        1.0\n",
              "min        1.0\n",
              "25%        1.5\n",
              "50%        2.0\n",
              "75%        2.5\n",
              "max        3.0\n",
              "\n",
              "Including only string columns in a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(include=[object])  # doctest: +SKIP\n",
              "       object\n",
              "count       3\n",
              "unique      3\n",
              "top         a\n",
              "freq        1\n",
              "\n",
              "Including only categorical columns from a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(include=[&#x27;category&#x27;])\n",
              "       categorical\n",
              "count            3\n",
              "unique           3\n",
              "top              d\n",
              "freq             1\n",
              "\n",
              "Excluding numeric columns from a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(exclude=[np.number])  # doctest: +SKIP\n",
              "       categorical object\n",
              "count            3      3\n",
              "unique           3      3\n",
              "top              f      a\n",
              "freq             1      1\n",
              "\n",
              "Excluding object columns from a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(exclude=[object])  # doctest: +SKIP\n",
              "       categorical  numeric\n",
              "count            3      3.0\n",
              "unique           3      NaN\n",
              "top              f      NaN\n",
              "freq             1      NaN\n",
              "mean           NaN      2.0\n",
              "std            NaN      1.0\n",
              "min            NaN      1.0\n",
              "25%            NaN      1.5\n",
              "50%            NaN      2.0\n",
              "75%            NaN      2.5\n",
              "max            NaN      3.0</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 11734);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPFOjhnK06Xx",
        "outputId": "0f677e0d-d223-419a-a6ef-3724e06c3a03"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYVs3z9r08gj",
        "outputId": "dfa8ff24-ee76-4915-ebfb-ee4f8dd8042f"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 32 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30), int64(1), object(1)\n",
            "memory usage: 142.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no any biasness of the Dataset"
      ],
      "metadata": {
        "id": "c2vFK6PX1Qut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Label Encoding"
      ],
      "metadata": {
        "id": "NUpGEcRY1V7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"diagnosis\"]=df[\"diagnosis\"].map({\"M\":1,\"B\":0})\n",
        "x=df.drop(columns=[\"diagnosis\",\"id\"])\n",
        "y=df[\"diagnosis\"]"
      ],
      "metadata": {
        "id": "D6yOLINF1iQp"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Training Testing and Spliting Data"
      ],
      "metadata": {
        "id": "vyFJX03J2_EC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=101)\n",
        "sc=StandardScaler()\n",
        "x_train=sc.fit_transform(x_train)\n",
        "x_test=sc.transform(x_test)\n",
        "#x_train\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "gp4CZgp21zUJ",
        "outputId": "a6f79e50-530d-4ccc-d880-8ed043210b65"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "      ..\n",
              "564    1\n",
              "565    1\n",
              "566    1\n",
              "567    1\n",
              "568    0\n",
              "Name: diagnosis, Length: 569, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "MwhoU_6J4Xbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train\n",
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "1lYwSZ3k4kCO",
        "outputId": "3fc94da1-bcdf-4402-f7e3-32281fe12a8b"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "464    0\n",
              "454    0\n",
              "447    0\n",
              "363    0\n",
              "241    0\n",
              "      ..\n",
              "552    0\n",
              "393    1\n",
              "75     1\n",
              "337    1\n",
              "523    0\n",
              "Name: diagnosis, Length: 426, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>426 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Apply Various Machine Learning Algorithm"
      ],
      "metadata": {
        "id": "ruoO99Gj3YBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.decision Tree"
      ],
      "metadata": {
        "id": "P2dKBbz56MXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model=DecisionTreeClassifier(random_state=41)\n",
        "\n",
        "model.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "print(\"classification report \",classification_report(y_test,y_pred))\n",
        "print(\"confusion matrix \",confusion_matrix(y_test,y_pred))\n",
        "print(f\"accuracy {accuracy_score(y_test,y_pred)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syv_WvAm9QCl",
        "outputId": "199f3b65-3ea5-4fba-cd2f-0535d4193238"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classification report                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93        88\n",
            "           1       0.88      0.91      0.89        55\n",
            "\n",
            "    accuracy                           0.92       143\n",
            "   macro avg       0.91      0.91      0.91       143\n",
            "weighted avg       0.92      0.92      0.92       143\n",
            "\n",
            "confusion matrix  [[81  7]\n",
            " [ 5 50]]\n",
            "accuracy 0.916083916083916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Random Forest"
      ],
      "metadata": {
        "id": "f9bGj9gt9u1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rnd_for=RandomForestClassifier(random_state=101)\n",
        "\n",
        "rnd_for.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "print(\"classification report \",classification_report(y_test,y_pred))\n",
        "print(\"confusion matrix \",confusion_matrix(y_test,y_pred))\n",
        "print(f\"accuracy {accuracy_score(y_test,y_pred)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByOllwzv9rV-",
        "outputId": "04d8fcfd-1208-43e0-c415-fd4b5f637698"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classification report                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93        88\n",
            "           1       0.88      0.91      0.89        55\n",
            "\n",
            "    accuracy                           0.92       143\n",
            "   macro avg       0.91      0.91      0.91       143\n",
            "weighted avg       0.92      0.92      0.92       143\n",
            "\n",
            "confusion matrix  [[81  7]\n",
            " [ 5 50]]\n",
            "accuracy 0.916083916083916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. SVM"
      ],
      "metadata": {
        "id": "5k2vld8QAfhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "svm_mod=SVC(kernel=\"linear\",random_state=101)\n",
        "svm_mod.fit(x_train,y_train)\n",
        "svm_pred=svm_mod.predict(x_test)\n",
        "print(\"classification report \",classification_report(y_test,y_pred))\n",
        "print(\"confusion matrix \",confusion_matrix(y_test,y_pred))\n",
        "print(f\"accuracy {accuracy_score(y_test,y_pred)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYQ7sYa9AqcS",
        "outputId": "98f6c1ce-9cda-4e4d-9980-ae56a43ae2dd"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classification report                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93        88\n",
            "           1       0.88      0.91      0.89        55\n",
            "\n",
            "    accuracy                           0.92       143\n",
            "   macro avg       0.91      0.91      0.91       143\n",
            "weighted avg       0.92      0.92      0.92       143\n",
            "\n",
            "confusion matrix  [[81  7]\n",
            " [ 5 50]]\n",
            "accuracy 0.916083916083916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. NAIVE BAYES"
      ],
      "metadata": {
        "id": "k7CTju5LDOMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Initialize and train the Naive Bayes model\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "nb_predictions = nb_model.predict(x_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Naive Bayes\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, nb_predictions))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, nb_predictions))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, nb_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcKKytAlDcxU",
        "outputId": "d843ddc7-3f5a-433b-94ac-1b788b4fbfea"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes\n",
            "Accuracy: 0.9300699300699301\n",
            "Confusion Matrix:\n",
            " [[82  6]\n",
            " [ 4 51]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94        88\n",
            "           1       0.89      0.93      0.91        55\n",
            "\n",
            "    accuracy                           0.93       143\n",
            "   macro avg       0.92      0.93      0.93       143\n",
            "weighted avg       0.93      0.93      0.93       143\n",
            "\n"
          ]
        }
      ]
    }
  ]
}